{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ejemplo adaptado del libro **Deep Learning with Python** (François Chollet, Manning Publications, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación\n",
    "\n",
    "Para utilizar Keras, primero instalamos TensorFlow y, a continuación, instalamos Keras junto con otras bibliotecas necesarias..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalación del backend de Keras (TensorFlow)\n",
    "\n",
    "Usamos la biblioteca Tensorflow, para lo cual hemos de instalarla previamente. En una instalación de Python de 64 bits, ejecutamos el siguiente comando:\n",
    "\n",
    "`pip3 install --upgrade tensorflow` \n",
    "\n",
    "Si disponemos de GPU en nuestro ordenador, podemos aprovecharla instalando la versión de Tensorflow con soporte para GPU:\n",
    "\n",
    "`pip3 install --upgrade tensorflow-gpu`\n",
    "\n",
    "Posiblemente, también tendremos que actualizar las bibliotecas de Microsoft Visual C++ (https://www.microsoft.com/en-us/download/details.aspx?id=53587) y, obviamente, instalar las bibliotecas correspondientes de NVIDIA para nuestra GPU (p.ej. cuDNN v6.0 para TensorFlow 1.3.0, https://developer.nvidia.com/rdp/cudnn-download).\n",
    "\n",
    "Cuando tenemos todo en orden, ya podemos utilizar Tensorflow desde Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos con un simple (e inútil) \"Hola mundo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World'\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(\"Hello World\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(x))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida que obtenemos con la ejecución de lo anterior será una cadena `b'Hello World'`. Si es así, ya podemos empezar a trabajar con TensorFlow en nuestro ordenador..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instalación de bibliotecas auxiliares (NumPy & SciPy)\n",
    "\n",
    "Instalamos NumPy y SciPy usando sus 'wheels' (un ZIP estándar en el que se distribuyen los paquetes de Python).\n",
    "\n",
    "- Si no lo tenemos, instalamos el paquete 'wheel'...\n",
    "\n",
    "`\tpip install wheel`\n",
    "\n",
    "- Descargamos los paquetes de NumPy y SciPy de las siguiente páginas\n",
    "\n",
    "\thttp://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy\n",
    "\n",
    "    http://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy\n",
    "\n",
    "\n",
    "- Instalamos una serie de paquetes utilizando pip:\n",
    "\n",
    "\n",
    "`   pip install numpy-1.13.3+mkl-cp36-cp36m-win_amd64.whl`\n",
    "\n",
    "`\tpip install scipy-0.19.1-cp36-cp36m-win_amd64.whl`\n",
    "\n",
    "\n",
    "`\tpip install numpy scipy`\n",
    "\n",
    "`\tpip install scikit-learn`\n",
    "\n",
    "`\tpip install pillow`\n",
    "\n",
    "`\tpip install h5py`\n",
    "\n",
    "\n",
    "### 3. Instalación de Keras\n",
    "\n",
    "Por último, instalamos Keras en sí:\n",
    "\n",
    "`\tpip3 install --upgrade keras`\n",
    "\n",
    "Más información: https://www.pyimagesearch.com/2016/11/14/installing-keras-with-tensorflow-backend/\n",
    "\n",
    "Si hemos realizado correctamente la instalación, podremos ejecutar el siguiente fragmento de código:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del fragmento de código anterior se iniciará con un mensaje informativo del tipo `Using TensorFlow backend.` seguido de una línea en la que se mostrará la versión de Keras que hayamos instalado en nuestro sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El conjunto de datos MNIST\n",
    "\n",
    "MNIST es uno de los conjuntos de datos con los que podemos trabajar directamente en Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los 11MB del conjunto de datos los descargamos, con la línea anterior, en cuatro arrays de NumPy. Esos cuatro arrays contienen los conjuntos de entrenamiento y de prueba del conjunto de datos MNIST, dos para las imágenes de 28x28 píxeles y otros dos para sus correspondientes etiquetas.\n",
    "\n",
    "El conjunto de entrenamiento contiene 60000 imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[5 0 4 ..., 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de prueba contiene 10000 imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "[7 2 1 ..., 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar con las imágenes del conjunto de datos, primero las normalizamos. En lugar de tener imágenes con píxeles de 8 bits, de 0 a 255, trabajaremos con números en coma flotante de 0 a 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, codificaremos las etiquetas como vectores 'one-hot' (en lugar de un número, usaremos un vector de ceros con un uno en la posición de la clase correcta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra primera red neuronal en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras proporciona un API de alto nivel (con respecto a TensorFlow) en el que sólo tenemos que definir la topología de nuestra red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Una red neuronal con una capa oculta de unidades lineales rectificadas y una capa de salida softmax\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar la red, primero tenemos que \"prepararla\" especificando una función de pérdida o error (loss function), un optimizador (el algoritmo que utilizaremos para ajustar sus parámetros iterativamente) y las métricas que deseamos ir evaluando para monitorizar su funcionamiento (p.ej. la precisión obtenida con la red):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación de la red\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos en condiciones de entrenar la red, que en Keras hacemos llamando al método `fit` de nuestra red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s - loss: 0.2554 - acc: 0.9262     \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.1029 - acc: 0.9695     \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.0670 - acc: 0.9800     \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.0497 - acc: 0.9849     \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.0368 - acc: 0.9890     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e281f70390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras unos segundos, podemos llegar a obtener una red capaz de clasificar correctamente más del 98% de los ejemplos del conjunto de entrenamiento. Sin embargo, no es ésta la precisión que realmente nos interesa, sino la que se obtiene sobre el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10000 [============================>.] - ETA: 0stest_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, lo normal es que la precisión sobre el conjunto de prueba sea algo inferior a la obtenida sobre el conjunto de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
